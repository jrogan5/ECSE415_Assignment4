{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECSE 415 - Assignment 4: Object Recognition\n",
    "## Road Signs Detection\n",
    "\n",
    "**Dataset:** Road Signs Detection (Kaggle)\n",
    "\n",
    "**Task:** Implement and evaluate object detection models for traffic sign recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 CUDA Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if cuda_available else 'cpu')\n",
    "\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle ultralytics torchvision torchmetrics pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class mapping\n",
    "CLASS_NAMES = {\n",
    "    0: 'Speed Limit 80', 1: 'Speed Limit 50', 2: 'Green Light', 3: 'Speed Limit 90',\n",
    "    4: 'Speed Limit 40', 5: 'Speed Limit 120', 6: 'Stop', 7: 'Speed Limit 60',\n",
    "    8: 'Speed Limit 70', 9: 'Speed Limit 20', 10: 'Speed Limit 110', 11: 'Red Light',\n",
    "    12: 'Speed Limit 30', 13: 'Speed Limit 100'\n",
    "}\n",
    "NUM_CLASSES = 14\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('/content/traffic_signs')\n",
    "TRAIN_IMG_DIR = DATA_DIR / 'train' / 'images'\n",
    "TRAIN_LBL_DIR = DATA_DIR / 'train' / 'labels'\n",
    "TEST_IMG_DIR = DATA_DIR / 'test' / 'images'\n",
    "\n",
    "# Training parameters\n",
    "IMG_SIZE = 416\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LR = 0.001\n",
    "TRAIN_VAL_SPLIT = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle API credentials\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp /content/drive/MyDrive/Kaggle_API/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract dataset\n",
    "# Replace 'competition-name' with actual competition name\n",
    "# !kaggle competitions download -c road-signs-detection\n",
    "# !unzip -q road-signs-detection.zip -d /content/traffic_signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images and annotations\n",
    "train_images = list(TRAIN_IMG_DIR.glob('*.jpg'))\n",
    "train_labels = list(TRAIN_LBL_DIR.glob('*.txt'))\n",
    "test_images = list(TEST_IMG_DIR.glob('*.jpg'))\n",
    "\n",
    "print(f\"Training images: {len(train_images)}\")\n",
    "print(f\"Training labels: {len(train_labels)}\")\n",
    "print(f\"Test images: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse YOLO annotations and count class distribution\n",
    "def parse_yolo_labels(label_dir):\n",
    "    class_counts = {i: 0 for i in range(NUM_CLASSES)}\n",
    "    total_objects = 0\n",
    "    \n",
    "    for label_file in Path(label_dir).glob('*.txt'):\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                class_id = int(line.split()[0])\n",
    "                class_counts[class_id] += 1\n",
    "                total_objects += 1\n",
    "    \n",
    "    return class_counts, total_objects\n",
    "\n",
    "class_counts, total_objects = parse_yolo_labels(TRAIN_LBL_DIR)\n",
    "print(f\"Total objects: {total_objects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "classes = [CLASS_NAMES[i] for i in range(NUM_CLASSES)]\n",
    "counts = [class_counts[i] for i in range(NUM_CLASSES)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(NUM_CLASSES), counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.xticks(range(NUM_CLASSES), classes, rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images with bounding boxes\n",
    "def draw_yolo_boxes(img_path, label_path, class_names):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:5])\n",
    "            \n",
    "            # Convert YOLO format to pixel coordinates\n",
    "            x1 = int((x_center - width/2) * w)\n",
    "            y1 = int((y_center - height/2) * h)\n",
    "            x2 = int((x_center + width/2) * w)\n",
    "            y2 = int((y_center + height/2) * h)\n",
    "            \n",
    "            # Draw box and label\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = class_names[class_id]\n",
    "            cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Display 5 sample images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, ax in enumerate(axes):\n",
    "    img_path = train_images[i]\n",
    "    label_path = TRAIN_LBL_DIR / f\"{img_path.stem}.txt\"\n",
    "    \n",
    "    if label_path.exists():\n",
    "        img = draw_yolo_boxes(img_path, label_path, CLASS_NAMES)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"Sample {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split image paths\n",
    "train_imgs, val_imgs = train_test_split(\n",
    "    train_images, \n",
    "    train_size=TRAIN_VAL_SPLIT, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(train_imgs)} images\")\n",
    "print(f\"Validation set: {len(val_imgs)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Model - YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prepare Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YOLO data.yaml configuration\n",
    "data_yaml = f\"\"\"\n",
    "path: {DATA_DIR}\n",
    "train: train/images\n",
    "val: train/images\n",
    "\n",
    "nc: {NUM_CLASSES}\n",
    "names: {list(CLASS_NAMES.values())}\n",
    "\"\"\"\n",
    "\n",
    "with open(DATA_DIR / 'data.yaml', 'w') as f:\n",
    "    f.write(data_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pretrained YOLOv8 model\n",
    "model_yolo = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train\n",
    "results = model_yolo.train(\n",
    "    data=str(DATA_DIR / 'data.yaml'),\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    device=0 if cuda_available else 'cpu',\n",
    "    project='yolo_baseline',\n",
    "    name='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation metrics\n",
    "metrics = model_yolo.val()\n",
    "\n",
    "print(f\"mAP@50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@50-95: {metrics.box.map:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on validation set\n",
    "results = model_yolo.predict(source=str(val_imgs[0]), save=True, conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model Architecture\n",
    "\n",
    "Implement custom object detection model (e.g., RetinaNet, Faster R-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model implementation placeholder\n",
    "# TODO: Implement custom detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop placeholder\n",
    "# TODO: Implement training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation placeholder\n",
    "# TODO: Compute F1, mAP@50, mAP@50-95, confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization placeholder\n",
    "# TODO: Display predictions on validation images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Generalization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External image test placeholder\n",
    "# TODO: Test on external traffic sign image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Kaggle Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "predictions = []\n",
    "\n",
    "for img_path in test_images:\n",
    "    results = model_yolo.predict(source=str(img_path), conf=0.25, verbose=False)\n",
    "    \n",
    "    # Extract boxes\n",
    "    for idx, result in enumerate(results[0].boxes.data.cpu().numpy()):\n",
    "        x1, y1, x2, y2, conf, class_id = result\n",
    "        \n",
    "        # Convert to YOLO format (normalized)\n",
    "        w, h = IMG_SIZE, IMG_SIZE\n",
    "        x_center = ((x1 + x2) / 2) / w\n",
    "        y_center = ((y1 + y2) / 2) / h\n",
    "        width = (x2 - x1) / w\n",
    "        height = (y2 - y1) / h\n",
    "        \n",
    "        predictions.append({\n",
    "            'ID': f\"{img_path.stem}_{idx}\",\n",
    "            'class_label': int(class_id),\n",
    "            'x_center': x_center,\n",
    "            'y_center': y_center,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Ensure all required IDs are present (match sample_submission.csv)\n",
    "# Load sample submission if available\n",
    "# sample_submission = pd.read_csv('sample_submission.csv')\n",
    "# submission_df = submission_df.merge(sample_submission[['ID']], on='ID', how='right')\n",
    "\n",
    "# Save\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission file created with {len(submission_df)} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit to Kaggle\n",
    "# !kaggle competitions submit -c road-signs-detection -f submission.csv -m \"Submission message\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
